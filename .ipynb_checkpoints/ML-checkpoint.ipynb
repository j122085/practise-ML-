{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 類神經 深度學習Ｐ２９　３０　３１"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "data=iris.data\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels=iris.target\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp=MLPClassifier(random_state=1)\n",
    "mlp.fit(data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#預測項目是哪類\n",
    "mlp.predict(np.array([[1,3,4,6],[4,3,1,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#預測每個項目是哪類的機率 \n",
    "mlp.predict_proba(data)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=mlp.predict(data)\n",
    "#用accuracy_score計算與真實數據的正確率\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(labels,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "data_train, data_test, labels_train, labels_test =train_test_split(data,labels,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#對數據做正規化的動作(減去平均值、縮放成一單位)，可以改進效能!!!\n",
    "scarler=StandardScaler()\n",
    "scarler.fit(data)\n",
    "data_train_std=scarler.transform(data_train)\n",
    "data_test_std=scarler.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#多層類神經網路分類器 ()\n",
    "    #random_state=1初始亂數值設定永遠相同 \n",
    "    #hidden_layer_sizes=(200,100)有兩層隱藏層，分別有200跟100個神經元 預設單層100\n",
    "    #activation='identity', 'logistic', 'tanh', 'relu' 啟動函數有四種 預設為'relu'\n",
    "        #'relu'預設，f(x)=max(0,x) 95%\n",
    "        #'logistic'f(x)=1/(1+exp(x)) 對事件的機率有興趣時使用 31%\n",
    "        #'identity'f(x)=x 97% \n",
    "        #'tanh'??? 97%\n",
    "    #max_iter=500跌代次數，重複訓練的次數 預設為200\n",
    "mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(200,100,),activation=\"tanh\",max_iter=500)\n",
    "#訓練\n",
    "mlp.fit(data_train_std,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#預測\n",
    "pred=mlp.predict(data_test_std)\n",
    "print(\"Misclassified samples: {}\".format((labels_test != pred).sum()))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(labels_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numpy_array可比較多項\n",
    "np.array([1,2,3])!=np.array([1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#可直接計算True數量\n",
    "(np.array([1,2,3])!=np.array([1,3,4])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#array資料有兩維度，因此中括號內  逗號左邊是選擇外層的維度,右邊是內層維度，但如果該層不做篩選，要加上 : 而不能全部空白\n",
    "test=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "weightValue=1000\n",
    "biasValue1=5000\n",
    "biasValue2=-5000\n",
    "x=np.array(range(-10,11))\n",
    "plt.axis([-10,10,-1,10])\n",
    "print(\"The step function starts at {} and ends at {}\".format(-biasValue1/weightValue,-biasValue2/weightValue))\n",
    "y1=1.0/(1.0+numpy.exp(-weightValue*x - biasValue1))\n",
    "y2=1.0/(1.0+numpy.exp(-weightValue*x - biasValue2))\n",
    "w=5\n",
    "y=y1*w-y2*w\n",
    "plt.plot(x,y,lw=2,color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tanh(x):     \n",
    "    return (1.0 - numpy.exp(-2*x))/(1.0 + numpy.exp(-2*x))\n",
    "\n",
    "def tanh_derivative(x):     \n",
    "    return (1 + tanh(x))*(1 - tanh(x))\n",
    "    \n",
    "class NeuralNetwork:\n",
    "    #network consists of a list of integers, indicating \n",
    "    #the number of neurons in each layer\n",
    "    def __init__(self, net_arch): \n",
    "        numpy.random.seed(0)                  \n",
    "        self.activity = tanh         \n",
    "        self.activity_derivative = tanh_derivative \n",
    "        self.layers = len(net_arch)         \n",
    "        self.steps_per_epoch = 1000\n",
    "        self.arch = net_arch        \n",
    "\n",
    "        self.weights = []         \n",
    "        #range of weight values (-1,1)         \n",
    "        for layer in range(len(net_arch) - 1):             \n",
    "            w = 2*numpy.random.rand(net_arch[layer] + 1, net_arch[layer+1]) - 1           \n",
    "            self.weights.append(w)\n",
    "\n",
    "    def fit(self, data, labels, learning_rate=0.1, epochs=10):         \n",
    "        #Add bias units to the input layer         \n",
    "        ones = numpy.ones((1, data.shape[0]))        \n",
    "        Z = numpy.concatenate((ones.T, data), axis=1)\n",
    "        training = epochs*self.steps_per_epoch\n",
    "\n",
    "\n",
    "        for k in range(training):             \n",
    "            if k % self.steps_per_epoch == 0:                  \n",
    "                #print ('epochs:', k/self.steps_per_epoch)    \n",
    "                print('epochs: {}'.format(k/self.steps_per_epoch))              \n",
    "                for s in data:                     \n",
    "                    print(s, nn.predict(s))\n",
    "\n",
    "            sample = numpy.random.randint(data.shape[0])            \n",
    "            y = [Z[sample]] \n",
    "\n",
    "            for i in range(len(self.weights)-1):                     \n",
    "                activation = numpy.dot(y[i], self.weights[i])                         \n",
    "                activity = self.activity(activation)  \n",
    "                #add the bias for the next layer                     \n",
    "                activity = numpy.concatenate((numpy.ones(1), numpy.array(activity)))                      \n",
    "                y.append(activity)   \n",
    "             \n",
    "            #last layer              \n",
    "            activation = numpy.dot(y[-1], self.weights[-1])             \n",
    "            activity = self.activity(activation)             \n",
    "            y.append(activity)\n",
    "                    \n",
    "            #error for the output layer             \n",
    "            error = labels[sample] - y[-1]             \n",
    "            delta_vec = [error * self.activity_derivative(y[-1])] \n",
    "\n",
    "            #we need to begin from the back from the next to last layer\n",
    "            for i in range(self.layers-2, 0, -1):  \n",
    "                #delta_vec [1].dot(self.weights[i][1:].T)                \n",
    "                error = delta_vec[-1].dot(self.weights[i][1:].T) \n",
    "                error = error*self.activity_derivative(y[i][1:])               \n",
    "                delta_vec.append(error)\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            delta_vec.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = y[i].reshape(1, nn.arch[i]+1) \n",
    " \n",
    "                delta = delta_vec[i].reshape(1, nn.arch[i+1])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "    def predict(self, x): \n",
    "        val = numpy.concatenate((numpy.ones(1).T, numpy.array(x)))      \n",
    "        for i in range(0, len(self.weights)):\n",
    "            val = self.activity(numpy.dot(val, self.weights[i]))\n",
    "            val = numpy.concatenate((numpy.ones(1).T, numpy.array(val)))\n",
    "            \n",
    "        return val[1]\n",
    "\n",
    "    def plot_decision_regions(self, X, y, points=200):\n",
    "        markers = ('o', '^')\n",
    "        colors = ('red', 'blue')\n",
    "        cmap = ListedColormap(colors)\n",
    "        # plot the decision surface\n",
    "        x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        \n",
    "        resolution = max(x1_max - x1_min, x2_max - x2_min)/float(points)\n",
    "        #resolution = 0.01\n",
    "     \n",
    "        xx1, xx2 = numpy.meshgrid(numpy.arange(x1_min, x1_max, resolution), numpy.arange(x2_min, x2_max, resolution))\n",
    "        input = numpy.array([xx1.ravel(), xx2.ravel()]).T \n",
    "        Z = numpy.empty(0)\n",
    "        for i in range(input.shape[0]):\n",
    "            val = nn.predict(numpy.array(input[i]))\n",
    "            if val < 0.5: val = 0 \n",
    "            if val >= 0.5: val = 1\n",
    "            Z = numpy.append(Z, val)\n",
    "\n",
    "        Z = Z.reshape(xx1.shape)\n",
    "        \n",
    "        plt.pcolormesh(xx1, xx2, Z, cmap=cmap)\n",
    "        plt.xlim(xx1.min(), xx1.max())\n",
    "        plt.ylim(xx2.min(), xx2.max())\n",
    "        # plot all samples\n",
    "\n",
    "        classes = [\"False\", \"True\"]\n",
    "        for idx, cl in enumerate(numpy.unique(y)):\n",
    "            plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=1.0, c=cmap(idx), marker=markers[idx], s=80, label=classes[idx])\n",
    "            \n",
    "        plt.xlabel('x-axis')            \n",
    "        plt.ylabel('y-axis')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "\n",
    "    X = numpy.array([[0, 0],\n",
    "                     [0, 1],\n",
    "                     [1, 0],\n",
    "                     [1, 1]])\n",
    "\n",
    "    y = numpy.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y, epochs=10)\n",
    "\n",
    "    print (\"Final prediction\")\n",
    "    for s in X:\n",
    "        print(s, nn.predict(s))\n",
    "        \n",
    "    nn.plot_decision_regions(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 圖像辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#數字圖資料集\n",
    "(X_train,Y_train),(X_test,Y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將60000*28*28矩陣轉成60000*784\n",
    "X_train=X_train.reshape(60000,784)\n",
    "X_test=X_test.reshape(10000,784)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#數字答案為0-9 轉換成0與1的元素向量  如4>[0,0,0,0,1,0,0,0,0,0] 、2>[0,0,1,0,0,0,0,0,0,0]\n",
    "classes=10\n",
    "Y_train=np_utils.to_categorical(Y_train,classes)\n",
    "Y_test=np_utils.to_categorical(Y_test,classes)\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=784#像速\n",
    "batch_size=100#每批樣本大小\n",
    "hidden_neurons=50#隱藏層神經元\n",
    "epochs=10#處理幾輪\n",
    "# main(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()  #定義model\n",
    "model.add(Dense(hidden_neurons,input_dim=input_size)) #加入層(緊密層) 產出個數100. 輸入個數784 次元\n",
    "model.add(Activation('sigmoid')) #啟動函數\n",
    "model.add(Dense(classes,input_dim=hidden_neurons))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#成本函數categorical_crossentropy(交叉熵)  最佳化工具sgd(梯度下降)\n",
    "model.compile(loss=\"categorical_crossentropy\",metrics=['accuracy'],optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      " 6700/48000 [===>..........................] - ETA: 0s - loss: 0.2882 - acc: 0.9224"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.3044 - acc: 0.9183 - val_loss: 0.2996 - val_acc: 0.9196\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2925 - acc: 0.9207 - val_loss: 0.2899 - val_acc: 0.9227\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2869 - acc: 0.9228 - val_loss: 0.2764 - val_acc: 0.9266\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2785 - acc: 0.9231 - val_loss: 0.2789 - val_acc: 0.9254\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2731 - acc: 0.9253 - val_loss: 0.2708 - val_acc: 0.9258\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2667 - acc: 0.9276 - val_loss: 0.2647 - val_acc: 0.9285\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2599 - acc: 0.9288 - val_loss: 0.2620 - val_acc: 0.9287\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2541 - acc: 0.9308 - val_loss: 0.2666 - val_acc: 0.9248\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2486 - acc: 0.9313 - val_loss: 0.2520 - val_acc: 0.9297\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2453 - acc: 0.9311 - val_loss: 0.2475 - val_acc: 0.9308\n"
     ]
    }
   ],
   "source": [
    "#訓練、batch_size=每批用多少資料、nb_epoch處理幾次 、verbose=1(每個步驟都印出)、validation_split=0.2(20%資料用來驗證)\n",
    "train_history=model.fit(X_train,Y_train,batch_size=batch_size,validation_split=0.2,nb_epoch=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRES0kkQSERGtJJFEREQrSSQREdHKX5XbWpI5rbE4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c8c6a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#劃出準確度歷程\n",
    "import matplotlib.pyplot as plt\n",
    "def show_tarin_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train','validation'],loc=\"upper left\")\n",
    "    plt.show()\n",
    "show_tarin_history(train_history,'acc','val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21379c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#劃出loss\n",
    "show_tarin_history(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 56us/step\n",
      "Test accuracy: 0.9252\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test,Y_test,verbose=1)\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#取得加權矩陣 (取得784(像素)*50(隱藏層數) +  50的矩陣)\n",
    "weights=model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm #圖形種類\n",
    "import numpy\n",
    "w=weights[0].T #變成50*784\n",
    "\n",
    "# for neuron in range(hidden_neurons):\n",
    "#     plt.imshow(numpy.reshape(w[neuron],(28,28)),\n",
    "#     cmap=cm.Greys_r)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "fig = plt.figure() \n",
    "for neuron in range(hidden_neurons):         \n",
    "    ax = fig.add_subplot(10, 10, neuron+1) #給予50個空間\n",
    "    ax.axis(\"off\")#軸取消\n",
    "    ax.imshow(numpy.reshape(w[neuron], (28, 28)), cmap = cm.Greys_r)#取得第n個784轉換成28*28 cm,Greys_r灰階\n",
    "\n",
    "plt.savefig(\"neuron_images.png\", dpi=300)    \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x35a19240>,\n",
       " <keras.layers.core.Activation at 0x35711e10>,\n",
       " <keras.layers.core.Dense at 0x35711b70>,\n",
       " <keras.layers.core.Activation at 0x35900d68>]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 較複雜的圖(有色彩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#數字圖資料集\n",
    "(X_train,Y_train),(X_test,Y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#將60000*28*28矩陣轉成60000*784\n",
    "X_train=X_train.reshape(50000,3072)\n",
    "X_test=X_test.reshape(10000,3072)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(numpy.reshape(X_train[100],(32,32,3)))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#數字答案為0-9 轉換成0與1的元素向量  如4>[0,0,0,0,1,0,0,0,0,0] 、2>[0,0,1,0,0,0,0,0,0,0]\n",
    "classes=10\n",
    "Y_train=np_utils.to_categorical(Y_train,classes)\n",
    "Y_test=np_utils.to_categorical(Y_test,classes)\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=3072#像速\n",
    "batch_size=100#每批樣本大小\n",
    "hidden_neurons=100#隱藏層神經元\n",
    "epochs=10#處理幾輪\n",
    "# main(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()  #定義model\n",
    "model.add(Dense(3000,input_dim=input_size)) #加入層(緊密層) 產出個數3000(神經元). 輸入個數3072 次元\n",
    "model.add(Activation('sigmoid')) #啟動函數\n",
    "model.add(Dense(2000,input_dim=2000)) #加入層(緊密層) 產出個數2000(神經元). 輸入個數3000 次元\n",
    "model.add(Activation('sigmoid')) #啟動函數\n",
    "model.add(Dense(classes,input_dim=2000))  #加入層(緊密層) 產出個數10(神經元). 輸入個數2000 次元\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#成本函數categorical_crossentropy  最佳化工具sgd(梯度下降)\n",
    "model.compile(loss=\"categorical_crossentropy\",metrics=['accuracy'],optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#訓練、batch_size=每批用多少資料、nb_epoch處理幾次 、verbose=1(每個步驟都印出) validation_split=0.1(訓練90% 驗證10%)\n",
    "model.fit(X_train,Y_train,batch_size=batch_size,nb_epoch=epochs,validation_split=0.1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score=model.evaluate(X_test,Y_test,verbose=1)\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#取得加權矩陣 (取得784(像素)*50(隱藏層數) +  50的矩陣)\n",
    "weights=model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 受限波茲曼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "VISIBLE_NODES = 784\n",
    "HIDDEN_NODES = 400\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "\n",
    "input_placeholder = tf.placeholder(\"float\", shape=(None, VISIBLE_NODES))\n",
    "\n",
    "weights = tf.Variable(tf.random_normal((VISIBLE_NODES, HIDDEN_NODES), mean=0.0, stddev=1. / VISIBLE_NODES))\n",
    "hidden_bias = tf.Variable(tf.zeros([HIDDEN_NODES]))\n",
    "visible_bias = tf.Variable(tf.zeros([VISIBLE_NODES]))\n",
    "\n",
    "hidden_activation = tf.nn.sigmoid(tf.matmul(input_placeholder, weights) + hidden_bias)\n",
    "visible_reconstruction = tf.nn.sigmoid(tf.matmul(hidden_activation, tf.transpose(weights)) + visible_bias)\n",
    "\n",
    "final_hidden_activation = tf.nn.sigmoid(tf.matmul(visible_reconstruction, weights) + hidden_bias)\n",
    "\n",
    "positive_phase = tf.matmul(tf.transpose(input_placeholder), hidden_activation)\n",
    "negative_phase = tf.matmul(tf.transpose(visible_reconstruction), final_hidden_activation)\n",
    "\n",
    "weight_update = weights.assign_add(LEARNING_RATE * (positive_phase - negative_phase))\n",
    "visible_bias_update = visible_bias.assign_add(LEARNING_RATE *\n",
    "                                              tf.reduce_mean(input_placeholder - visible_reconstruction, 0))\n",
    "hidden_bias_update = hidden_bias.assign_add(LEARNING_RATE *\n",
    "                                            tf.reduce_mean(hidden_activation - final_hidden_activation, 0))\n",
    "\n",
    "train_op = tf.group(weight_update, visible_bias_update, hidden_bias_update)\n",
    "\n",
    "loss_op = tf.reduce_sum(tf.square(input_placeholder - visible_reconstruction))\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "session.run(tf.initialize_all_variables())\n",
    "\n",
    "current_epochs = 0\n",
    "\n",
    "for i in range(20):\n",
    "    total_loss = 0\n",
    "    while mnist.train.epochs_completed == current_epochs:\n",
    "        batch_inputs, batch_labels = mnist.train.next_batch(100)\n",
    "        _, reconstruction_loss = session.run([train_op, loss_op], feed_dict={input_placeholder: batch_inputs})\n",
    "        total_loss += reconstruction_loss\n",
    "\n",
    "    print(\"epochs %s loss %s\" % (current_epochs, reconstruction_loss))\n",
    "    current_epochs = mnist.train.epochs_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstruction=session.run(visible_reconstruction,feed_dict={input_placeholder:[mnist.train.images[0]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷積概念"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "#image為int(數字圖片編號)\n",
    "def main(image,im_filter):\n",
    "    im=X_train[image]\n",
    "    #定義新圖形、大小為圖片數據 寬-2*高-2\n",
    "    width=im.shape[0]\n",
    "    height=im.shape[1]\n",
    "    imC=numpy.zeros((width-2,height-2))\n",
    "    \n",
    "    \n",
    "    #進行卷積\n",
    "    for row in range(1,width-1):\n",
    "        for col in range(1,height-1):\n",
    "            for i in range(len(im_filter[0])):\n",
    "                for j in range(len(im_filter)):\n",
    "                    imC[row-1][col-1]+=im[row-1+i][col-1+j]*im_filter[i][j]\n",
    "#             #數字不大於255(灰皆色範圍)\n",
    "            if imC[row-1][col-1]>255:\n",
    "                imC[row-1][col-1]=255\n",
    "            elif imC[row-1][col-1]<0:\n",
    "                imC[row-1][col-1]=0\n",
    "    plt.imshow(im,cmap=cm.Greys_r)\n",
    "    plt.show()\n",
    "    plt.imshow(imC/255,cmap=cm.Greys_r)\n",
    "    plt.show()  \n",
    "    \n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    #載入資料\n",
    "    (X_train,Y_train),(X_test,Y_test)=mnist.load_data()\n",
    "    \n",
    "    #建立filter\n",
    "    blur=[[1./9,1./9,1./9],[1./9,1./9,1./9],[1./9,1./9,1./9]]\n",
    "    edges=[[1,1,1],[0,-8,0],[1,1,1]]\n",
    "    \n",
    "    #跑卷積\n",
    "    main(1,edges)\n",
    "    main(1,blur)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano\n",
    "import matplotlib.pyplot as plt\n",
    "import theano.tensor as T\n",
    "from theano.tensor.nnet import conv\n",
    "import skimage.data\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda update --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --ignore-installed scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=scipy.imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#數字圖資料集\n",
    "(X_train,Y_train),(X_test,Y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#將60000*28*28矩陣轉成60000*784\n",
    "X_train=X_train.reshape(60000,28,28,1)\n",
    "X_test=X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#數字答案為0-9 轉換成0與1的元素向量  如4>[0,0,0,0,1,0,0,0,0,0] 、2>[0,0,1,0,0,0,0,0,0,0]\n",
    "classes=10\n",
    "Y_train=np_utils.to_categorical(Y_train,classes)\n",
    "Y_test=np_utils.to_categorical(Y_test,classes)\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=784#像速\n",
    "batch_size=100#每批樣本大小\n",
    "hidden_neurons=200#隱藏層神經元\n",
    "epochs=30#處理幾輪\n",
    "# main(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_train/=255\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()  #定義model\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(28,28,1))) #加入層(緊密層) 產出個數100. 輸入個數784 次元\n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Convolution2D(32,(3,3))) #加入層(緊密層) 產出個數100. 輸入個數784 次元\n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(hidden_neurons)) \n",
    "model.add(Activation('relu'))      \n",
    "model.add(Dense(classes)) \n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#成本函數categorical_crossentropy  最佳化工具sgd(梯度下降)\n",
    "model.compile(loss=\"categorical_crossentropy\",metrics=['accuracy'],optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.2244 - acc: 0.9322\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0556 - acc: 0.9831\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.0378 - acc: 0.9885\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0286 - acc: 0.9915\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.0219 - acc: 0.9936\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0170 - acc: 0.9951\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0136 - acc: 0.9960\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0106 - acc: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6a66e1d0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#訓練、batch_size=每批用多少資料、nb_epoch處理幾次 、verbose=1(每個步驟都印出)\n",
    "model.fit(X_train,Y_train,batch_size=batch_size,nb_epoch=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 567us/step\n",
      "Test accuracy: 0.9889\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test,Y_test,verbose=1)\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#取得加權矩陣 (取得784(像素)*50(隱藏層數) +  50的矩陣)\n",
    "weights=model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 9 into shape (28,28,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-bb86a57f07be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneuron\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#給予50個空間\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"off\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#軸取消\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGreys_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#取得第n個784轉換成28*28 cm,Greys_r灰階\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"neuron_images.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;33m*\u001b[0m \u001b[1;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mraise\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meach\u001b[0m \u001b[0melement\u001b[0m \u001b[0mof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0ma\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mand\u001b[0m \u001b[0mthus\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mBa\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuppose\u001b[0m \u001b[0mthat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m       \u001b[0;31m`\u001b[0m\u001b[0mi\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m       \u001b[1;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mBa\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mposition\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mBchoices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msame\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 9 into shape (28,28,1)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm #圖形種類\n",
    "import numpy\n",
    "w=weights[0].T #變成50*784\n",
    "\n",
    "# for neuron in range(hidden_neurons):\n",
    "#     plt.imshow(numpy.reshape(w[neuron],(28,28)),\n",
    "#     cmap=cm.Greys_r)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "fig = plt.figure() \n",
    "for neuron in range(hidden_neurons):         \n",
    "    ax = fig.add_subplot(20, 20, neuron+1) #給予50個空間\n",
    "    ax.axis(\"off\")#軸取消\n",
    "    ax.imshow(numpy.reshape(w[neuron], (28, 28)), cmap = cm.Greys_r)#取得第n個784轉換成28*28 cm,Greys_r灰階\n",
    "\n",
    "plt.savefig(\"neuron_images.png\", dpi=300)    \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/8\n",
      " 1700/54000 [..............................] - ETA: 1:58 - loss: 1.7324 - acc: 0.5006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-c8bac6cb89f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adadelta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np     \n",
    "# np.random.seed(0)  #for reproducibility            \n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential #model\n",
    "from keras.layers import Dense, Activation #緊密層、啟動函數\n",
    "from keras.layers import Convolution2D, MaxPooling2D# 卷積、池化\n",
    "from keras.layers import Dropout, Flatten #隨機神經元退出 、平坦化\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 100     \n",
    "hidden_neurons = 200\n",
    "classes = 10     \n",
    "epochs = 8\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)     \n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')     \n",
    "X_test = X_test.astype('float32')     \n",
    "X_train /= 255     \n",
    "X_test /= 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train, classes)     \n",
    "Y_test = np_utils.to_categorical(Y_test, classes)\n",
    "\n",
    "model = Sequential() \n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(28, 28, 1))) #32種3*3的filters \n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, (3, 3)))  \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))  \n",
    "               \n",
    "model.add(Flatten())\n",
    " \n",
    "model.add(Dense(hidden_neurons)) \n",
    "model.add(Activation('relu'))      \n",
    "model.add(Dense(classes)) \n",
    "model.add(Activation('softmax'))\n",
    "     \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adadelta')\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split = 0.1, verbose=1)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 6.0131 - acc: 0.6197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x346ce160>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import utils\n",
    "\n",
    "(data, labels), (X_test, Y_test) = mnist.load_data()\n",
    "X_test=X_test.reshape(10000,784)\n",
    "data=data.reshape(60000,784)\n",
    "labels = utils.to_categorical(labels, num_classes=10)\n",
    "# 这部分返回一个张量\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# 层的实例是可调用的，它以张量为参数，并且返回一个张量\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 这部分创建了一个包含输入层和三个全连接层的模型\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels)  # 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b25a08dfd5ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mjson_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#將模型變json字串 可存放為文字檔\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#將json字串變成model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_string = model.to_json() #將模型變json字串 可存放為文字檔\n",
    "model = model_from_json(json_string) #將json字串變成model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets=3\n",
    "\n",
    "#每走一步輸入得到的數值\n",
    "def step(s,x,U,W):\n",
    "    return x*U+s*W\n",
    "\n",
    "#向後傳遞\n",
    "def forward(X,U,W):\n",
    "    S=np.zeros((number_of_samples,sequence_length+1))\n",
    "    for t in range(0,sequence_length):\n",
    "        S[:,t+1]=step(S[:,t],X[:,t],U,W)\n",
    "    return S\n",
    "#成本函數(均方誤差)\n",
    "# cost=np.sum((targets-y)**2)\n",
    "def bacjward(X,S,targets,W):\n",
    "    y=S[:,-1]\n",
    "    gS=2.0*(y-targets)\n",
    "    gU,gW=0,0\n",
    "    for k in range(sequence_len,0,-1):\n",
    "        gU+=np.sum(gS*X[:,k-1])\n",
    "        gW+=np.sum(gS*S[:,k-1])\n",
    "        gS=gS*W\n",
    "    return gU,gW\n",
    "\n",
    "learning_rate=0.0005\n",
    "parameters=(-2,0)\n",
    "for i in range(number_iterations):\n",
    "    S=forward(X,parameters(0),parameters(1))\n",
    "    gradients=backward(X,S,targets,parameters(1))\n",
    "    parameters=((p-gp*learning_rate) for p,gp in zip(parameters,gradients))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters=(-2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-188555973c63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "parameters(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
