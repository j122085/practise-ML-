{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headersStr=\"\"\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\n",
    "Accept-Encoding: gzip, deflate\n",
    "Accept-Language: zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7\n",
    "Authorization: Digest username=\"admin\", realm=\"Panasonic network device\", nonce=\"8f0852742b9bead8887192b4042285dd\", uri=\"/cgi-bin/camera?resolution=1280&quality=1&Language=12\", algorithm=MD5, response=\"55d9ebbffc0754a3d1733346f3a13271\", qop=auth, nc=00000001, cnonce=\"f9580196d9eba364\"\n",
    "Cache-Control: max-age=0\n",
    "Connection: keep-alive\n",
    "Cookie: Session=0\n",
    "Host: 172.20.26.10\n",
    "Upgrade-Insecure-Requests: 1\n",
    "User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36\"\"\"\n",
    "headers={i.split(\":\")[0]:i.split(\":\")[1].strip() for i in headersStr.split(\"\\n\")}\n",
    "paramsStr=\"\"\"resolution: 1280\n",
    "quality: 1\n",
    "Language: 12\"\"\"\n",
    "params={i.split(\":\")[0]:i.split(\":\")[1].strip() for i in paramsStr.split(\"\\n\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res=requests.get(\"http://172.20.26.10/cgi-bin/camera?resolution=1280&quality=1&Language=12\",params=params,headers=headers,stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=Image.open(BytesIO(res.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_img =Image.open(BytesIO(res.content))\n",
    "curr_img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "picArray=cv2.cvtColor(np.array(curr_img), cv2.COLOR_RGB2GRAY)\n",
    "# picArray=cv2.cvtColor(np.array(curr_img), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location=face_recognition.face_locations(picArray,model=\"cnn\")\n",
    "#location for RGB or GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aaa=picArray[location[0][0]:location[0][2],location[0][3]:location[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(aaa)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "headersStr=\"\"\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\n",
    "Accept-Encoding: gzip, deflate\n",
    "Accept-Language: zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7\n",
    "Authorization: Digest username=\"admin\", realm=\"Panasonic network device\", nonce=\"8f0852742b9bead8887192b4042285dd\", uri=\"/cgi-bin/camera?resolution=1280&quality=1&Language=12\", algorithm=MD5, response=\"55d9ebbffc0754a3d1733346f3a13271\", qop=auth, nc=00000001, cnonce=\"f9580196d9eba364\"\n",
    "Cache-Control: max-age=0\n",
    "Connection: keep-alive\n",
    "Cookie: Session=0\n",
    "Host: 172.20.26.10\n",
    "Upgrade-Insecure-Requests: 1\n",
    "User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36\"\"\"\n",
    "headers={i.split(\":\")[0]:i.split(\":\")[1].strip() for i in headersStr.split(\"\\n\")}\n",
    "paramsStr=\"\"\"resolution: 1280\n",
    "quality: 1\n",
    "Language: 12\"\"\"\n",
    "params={i.split(\":\")[0]:i.split(\":\")[1].strip() for i in paramsStr.split(\"\\n\")}\n",
    "\n",
    "res=requests.get(\"http://172.20.26.10/cgi-bin/mjpeg?resolution=1280x960&framerate=1&Language=0\",params=params,headers=headers,stream=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res.status_code\n",
    "\n",
    "# x=Image.open(BytesIO(res.content))\n",
    "\n",
    "# curr_img =Image.open(BytesIO(res.content))\n",
    "# curr_img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('http://172.20.26.10/cgi-bin/mjpeg')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "r = requests.get('http://172.20.26.10/cgi-bin/mjpeg', auth=('admin', 'a0000000'), stream=True)\n",
    "if(r.status_code == 200):\n",
    "    bytes = bytes()\n",
    "    for chunk in r.iter_content(chunk_size=1024):\n",
    "        bytes += chunk\n",
    "        a = bytes.find(b'\\xff\\xd8')\n",
    "        b = bytes.find(b'\\xff\\xd9')\n",
    "        if a != -1 and b != -1:\n",
    "            jpg = bytes[a:b+2]\n",
    "            bytes = bytes[b+2:]\n",
    "            i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            cv2.imshow('i', i)\n",
    "            if cv2.waitKey(1) == 27:\n",
    "                exit(0)\n",
    "else:\n",
    "    print(\"Received unexpected status code {}\".format(r.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "# 開啟影片檔案\n",
    "cap = cv2.VideoCapture(\"http://172.20.26.10/cgi-bin/mjpeg\")\n",
    "\n",
    "# Dlib 的人臉偵測器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 以迴圈從影片檔案讀取影格，並顯示出來\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # 偵測人臉\n",
    "    face_rects, scores, idx = detector.run(frame, 0)\n",
    "\n",
    "    # 取出所有偵測的結果\n",
    "    for i, d in enumerate(face_rects):\n",
    "        x1 = d.left()\n",
    "        y1 = d.top()\n",
    "        x2 = d.right()\n",
    "        y2 = d.bottom()\n",
    "        text = \"%2.2f(%d)\" % (scores[i], idx[i])\n",
    "\n",
    "        # 以方框標示偵測的人臉\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 4, cv2.LINE_AA)\n",
    "\n",
    "        # 標示分數\n",
    "        cv2.putText(frame, text, (x1, y1), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                0.7, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # 顯示結果\n",
    "    cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAM FACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "\n",
    "# This is a demo of running face recognition on live video from your webcam. It's a little more complicated than the\n",
    "# other example, but it includes some basic performance tweaks to make things run a lot faster:\n",
    "#   1. Process each video frame at 1/4 resolution (though still display it at full resolution)\n",
    "#   2. Only detect faces in every other frame of video.\n",
    "\n",
    "# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "# video_capture = cv2.VideoCapture(\"http://172.20.26.10/cgi-bin/mjpeg\")\n",
    "video_capture = cv2.VideoCapture(\"rtsp://172.20.26.10/Src/MediaInput/h264/stream_1/ch_\")\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "obama_image = face_recognition.load_image_file(r\"D:\\trydata\\face\\train\\Agu\\b.jpg\")\n",
    "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "\n",
    "# Load a second sample picture and learn how to recognize it.\n",
    "biden_image = face_recognition.load_image_file(r\"D:\\trydata\\face\\train\\WAVE\\jj.jpg\")\n",
    "biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    obama_face_encoding,\n",
    "    biden_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Agu\",\n",
    "    \"LittleWay\"\n",
    "]\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # If a match was found in known_face_encodings, just use the first one.\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_face_names[first_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train knn model for pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is an example of using the k-nearest-neighbors(knn) algorithm for face recognition.\n",
    "\n",
    "When should I use this example?\n",
    "This example is useful when you wish to recognize a large set of known people,\n",
    "and make a prediction for an unkown person in a feasible computation time.\n",
    "\n",
    "Algorithm Description:\n",
    "The knn classifier is first trained on a set of labeled(known) faces, and can then predict the person\n",
    "in an unkown image by finding the k most similar faces(images with closet face-features under eucledian distance) in its training set,\n",
    "and performing a majority vote(possibly weighted) on their label.\n",
    "For example, if k=3, and the three closest face images to the given image in the training set are one image of Biden and two images of Obama, \n",
    "The result would be 'Obama'.\n",
    "*This implemententation uses a weighted vote, such that the votes of closer-neighbors are weighted more heavily.\n",
    "\n",
    "Usage:\n",
    "-First, prepare a set of images of the known people you want to recognize.\n",
    " Organize the images in a single directory with a sub-directory for each known person.\n",
    "-Then, call the 'train' function with the appropriate parameters.\n",
    " make sure to pass in the 'model_save_path' if you want to re-use the model without having to re-train it. \n",
    "-After training the model, you can call 'predict' to recognize the person in an unknown image.\n",
    "\n",
    "NOTE: This example requires scikit-learn to be installed! You can install it with pip:\n",
    "$ pip3 install scikit-learn\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn import neighbors\n",
    "from os import listdir\n",
    "from os.path import isdir, join, isfile, splitext\n",
    "import pickle\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "import face_recognition\n",
    "from face_recognition import face_locations\n",
    "# from face_recognition.cli import image_files_in_folder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}\n",
    "\n",
    "def train(train_dir, model_save_path = \"\", n_neighbors = None, knn_algo = 'ball_tree', verbose=False):\n",
    "    \"\"\"\n",
    "    Trains a k-nearest neighbors classifier for face recognition.\n",
    "\n",
    "    :param train_dir: directory that contains a sub-directory for each known person, with its name.\n",
    "\n",
    "     (View in source code to see train_dir example tree structure)\n",
    "\n",
    "     Structure:\n",
    "        <train_dir>/\n",
    "        ├── <person1>/\n",
    "        │   ├── <somename1>.jpeg\n",
    "        │   ├── <somename2>.jpeg\n",
    "        │   ├── ...\n",
    "        ├── <person2>/\n",
    "        │   ├── <somename1>.jpeg\n",
    "        │   └── <somename2>.jpeg\n",
    "        └── ...\n",
    "    :param model_save_path: (optional) path to save model of disk\n",
    "    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified.\n",
    "    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\n",
    "    :param verbose: verbosity of training\n",
    "    :return: returns knn classifier that was trained on the given data.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for class_dir in listdir(train_dir):\n",
    "        if not isdir(join(train_dir, class_dir)):\n",
    "            continue\n",
    "        path=join(train_dir, class_dir)\n",
    "        for imgfile in listdir(path):\n",
    "            if \"jpg\" in imgfile or \"png\" in imgfile or \"jpeg\" in imgfile:\n",
    "                image = face_recognition.load_image_file(path+\"/\"+imgfile)\n",
    "                faces_bboxes = face_locations(image,model=\"cnn\")\n",
    "                if len(faces_bboxes) != 1:\n",
    "                    if verbose:\n",
    "                        print(\"image {} not fit for training: {}\".format(path+\"/\"+imgfile, \"didn't find a face\" if len(faces_bboxes) < 1 else \"found more than one face\"))\n",
    "                    continue\n",
    "                X.append(face_recognition.face_encodings(image, known_face_locations=faces_bboxes)[0])\n",
    "                y.append(class_dir)\n",
    "\n",
    "\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(round(sqrt(len(X))))\n",
    "        if verbose:\n",
    "            print(\"Chose n_neighbors automatically as:\", n_neighbors)\n",
    "\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "    if model_save_path != \"\":\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "    return knn_clf\n",
    "\n",
    "def predict(X_img_path, knn_clf = None, model_save_path =\"\", DIST_THRESH = .45):\n",
    "    \"\"\"\n",
    "    recognizes faces in given image, based on a trained knn classifier\n",
    "\n",
    "    :param X_img_path: path to image to be recognized\n",
    "    :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified.\n",
    "    :param model_save_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf.\n",
    "    :param DIST_THRESH: (optional) distance threshold in knn classification. the larger it is, the more chance of misclassifying an unknown person to a known one.\n",
    "    :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...].\n",
    "        For faces of unrecognized persons, the name 'N/A' will be passed.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isfile(X_img_path) or splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS:\n",
    "        raise Exception(\"invalid image path: {}\".format(X_img_path))\n",
    "\n",
    "    if knn_clf is None and model_save_path == \"\":\n",
    "        raise Exception(\"must supply knn classifier either thourgh knn_clf or model_save_path\")\n",
    "\n",
    "    if knn_clf is None:\n",
    "        with open(model_save_path, 'rb') as f:\n",
    "            knn_clf = pickle.load(f)\n",
    "\n",
    "    X_img = face_recognition.load_image_file(X_img_path)\n",
    "    X_faces_loc = face_locations(X_img)\n",
    "#     X_faces_loc = face_locations(X_img,model=\"cnn\")\n",
    "    if len(X_faces_loc) == 0:\n",
    "        return []\n",
    "\n",
    "    faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_faces_loc)\n",
    "\n",
    "\n",
    "    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\n",
    "\n",
    "    is_recognized = [closest_distances[0][i][0] <= DIST_THRESH for i in range(len(X_faces_loc))]\n",
    "\n",
    "    # predict classes and cull classifications that are not with high confidence\n",
    "    return [(pred, loc) if rec else (\"N/A\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_faces_loc, is_recognized)]\n",
    "\n",
    "def draw_preds(img_path, preds):\n",
    "    \"\"\"\n",
    "    shows the face recognition results visually.\n",
    "\n",
    "    :param img_path: path to image to be recognized\n",
    "    :param preds: results of the predict function\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    source_img = Image.open(img_path).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(source_img)\n",
    "    for pred in preds:\n",
    "        loc = pred[1]\n",
    "        name = pred[0]\n",
    "        # (top, right, bottom, left) => (left,top,right,bottom)\n",
    "        draw.rectangle(((loc[3], loc[0]), (loc[1],loc[2])), outline=\"red\")\n",
    "        draw.text((loc[3], loc[0] - 30), name, font=ImageFont.truetype(r'控制台\\所有控制台項目\\字型\\微軟正黑體\\msjhbd.ttf', 40))\n",
    "#         draw.text((loc[3], loc[0] - 30), name, font=ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', 30))\n",
    "#         draw.text((loc[3], loc[0] - 30), name)\n",
    "    plt.imshow(source_img)\n",
    "    plt.show()\n",
    "#     source_img.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainDir=r\"D:\\trydata\\face\\train\"\n",
    "    testDir=r\"D:\\trydata\\face\\test\"\n",
    "    model_save_path =r\"D:\\trydata\\face\\knnModel\\data.model\"\n",
    "    knn_clf = train(trainDir,model_save_path =model_save_path,verbose=True)\n",
    "    for img_path in listdir(testDir):\n",
    "        if \"jpg\" in img_path or \"png\" in img_path or \"jpeg\" in img_path:\n",
    "            preds = predict(join(testDir, img_path) ,knn_clf=knn_clf)\n",
    "            print(preds)\n",
    "            draw_preds(join(testDir, img_path), preds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# cam face +knns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\imgwarp.cpp:3483: error: (-215) ssize.width > 0 && ssize.height > 0 in function cv::resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d65508ef550d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# Resize frame of video to 1/4 size for faster face recognition processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0msmall_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;31m#     small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#     small_frame = cv2.resize(frame, (0, 0), fx=1, fy=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\imgwarp.cpp:3483: error: (-215) ssize.width > 0 && ssize.height > 0 in function cv::resize\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import face_recognition\n",
    "import cv2\n",
    "import pickle\n",
    "from PIL import Image, ImageFont\n",
    "# This is a demo of running face recognition on live video from your webcam. It's a little more complicated than the\n",
    "# other example, but it includes some basic performance tweaks to make things run a lot faster:\n",
    "#   1. Process each video frame at 1/4 resolution (though still display it at full resolution)\n",
    "#   2. Only detect faces in every other frame of video.\n",
    "\n",
    "# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(\"http://172.20.26.10/cgi-bin/mjpeg?resolution=1280x960&framerate=1&Language=0\")\n",
    "# video_capture = cv2.VideoCapture(\"rtsp://172.20.26.10/Src/MediaInput/h264/stream_1/ch_\")\n",
    "# video_capture = cv2.VideoCapture(\"rtsp://admin:w@w12321@172.20.26.10/video.h264\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_save_path=r\"D:\\trydata\\face\\knnModel\\data.model\"\n",
    "with open(model_save_path, 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "DIST_THRESH=0.45\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "#     small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "#     small_frame = cv2.resize(frame, (0, 0), fx=1, fy=1)\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "        \n",
    "        face_names = []\n",
    "        if len(face_encodings)>0:\n",
    "            closest_distances = knn_clf.kneighbors(face_encodings, n_neighbors=1)\n",
    "            is_recognized = [closest_distances[0][i][0] <= DIST_THRESH for i in range(len(face_locations))]\n",
    "            data=[(pred, loc) if rec else (\"N/A\", loc) for pred, loc, rec in zip(knn_clf.predict(face_encodings), face_locations, is_recognized)]\n",
    "            face_names=[i[0] for i in data]\n",
    "            print(face_names,time.asctime())\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "    \n",
    "\n",
    "    # Display the results\n",
    "    \n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "#         top *= 2\n",
    "#         right *= 2\n",
    "#         bottom *= 2\n",
    "#         left *= 2\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "        \n",
    "        \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.FONT_HERSHEY_DUPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(small_frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# 接收攝影機串流影像，採用多執行緒的方式，降低緩衝區堆疊圖幀的問題。\n",
    "class ipcamCapture:\n",
    "    def __init__(self, URL):\n",
    "        self.Frame = []\n",
    "        self.status = False\n",
    "        self.isstop = False\n",
    "\n",
    "    # 攝影機連接。\n",
    "        self.capture = cv2.VideoCapture(URL)\n",
    "\n",
    "    def start(self):\n",
    "    # 把程式放進子執行緒，daemon=True 表示該執行緒會隨著主執行緒關閉而關閉。\n",
    "        print('ipcam started!')\n",
    "        threading.Thread(target=self.queryframe, daemon=True, args=()).start()\n",
    "\n",
    "    def stop(self):\n",
    "    # 記得要設計停止無限迴圈的開關。\n",
    "        self.isstop = True\n",
    "        print('ipcam stopped!')\n",
    "\n",
    "    def getframe(self):\n",
    "    # 當有需要影像時，再回傳最新的影像。\n",
    "        return self.Frame\n",
    "\n",
    "    def queryframe(self):\n",
    "        while (not self.isstop):\n",
    "            self.status, self.Frame = self.capture.read()\n",
    "\n",
    "        self.capture.release()\n",
    "\n",
    "        \n",
    "URL = \"http://172.20.26.10/cgi-bin/mjpeg\"\n",
    "\n",
    "# 連接攝影機\n",
    "ipcam = ipcamCapture(URL)\n",
    "\n",
    "# 啟動子執行緒\n",
    "ipcam.start()\n",
    "\n",
    "# 暫停1秒，確保影像已經填充\n",
    "time.sleep(1)\n",
    "\n",
    "# 使用無窮迴圈擷取影像，直到按下Esc鍵結束\n",
    "while True:\n",
    "    # 使用 getframe 取得最新的影像\n",
    "    I = ipcam.getframe()\n",
    "\n",
    "    cv2.imshow('Image', I)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        ipcam.stop()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
