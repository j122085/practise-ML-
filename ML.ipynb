{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 類神經 深度學習Ｐ２９　３０　３１"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "data=iris.data\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels=iris.target\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp=MLPClassifier(random_state=1)\n",
    "mlp.fit(data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#預測項目是哪類\n",
    "mlp.predict(np.array([[1,3,4,6],[4,3,1,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#預測每個項目是哪類的機率 \n",
    "mlp.predict_proba(data)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=mlp.predict(data)\n",
    "#用accuracy_score計算與真實數據的正確率\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(labels,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "data_train, data_test, labels_train, labels_test =train_test_split(data,labels,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#對數據做正規化的動作(減去平均值、縮放成一單位)，可以改進效能!!!\n",
    "scarler=StandardScaler()\n",
    "scarler.fit(data)\n",
    "data_train_std=scarler.transform(data_train)\n",
    "data_test_std=scarler.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#多層類神經網路分類器 ()\n",
    "    #random_state=1初始亂數值設定永遠相同 \n",
    "    #hidden_layer_sizes=(200,100)有兩層隱藏層，分別有200跟100個神經元 預設單層100\n",
    "    #activation='identity', 'logistic', 'tanh', 'relu' 啟動函數有四種 預設為'relu'\n",
    "        #'relu'預設，f(x)=max(0,x) 95%\n",
    "        #'logistic'f(x)=1/(1+exp(x)) 對事件的機率有興趣時使用 31%\n",
    "        #'identity'f(x)=x 97% \n",
    "        #'tanh'??? 97%\n",
    "    #max_iter=500跌代次數，重複訓練的次數 預設為200\n",
    "mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(200,100,),activation=\"tanh\",max_iter=500)\n",
    "#訓練\n",
    "mlp.fit(data_train_std,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#預測\n",
    "pred=mlp.predict(data_test_std)\n",
    "print(\"Misclassified samples: {}\".format((labels_test != pred).sum()))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(labels_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numpy_array可比較多項\n",
    "np.array([1,2,3])!=np.array([1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#可直接計算True數量\n",
    "(np.array([1,2,3])!=np.array([1,3,4])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#array資料有兩維度，因此中括號內  逗號左邊是選擇外層的維度,右邊是內層維度，但如果該層不做篩選，要加上 : 而不能全部空白\n",
    "test=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "weightValue=1000\n",
    "biasValue1=5000\n",
    "biasValue2=-5000\n",
    "x=np.array(range(-10,11))\n",
    "plt.axis([-10,10,-1,10])\n",
    "print(\"The step function starts at {} and ends at {}\".format(-biasValue1/weightValue,-biasValue2/weightValue))\n",
    "y1=1.0/(1.0+numpy.exp(-weightValue*x - biasValue1))\n",
    "y2=1.0/(1.0+numpy.exp(-weightValue*x - biasValue2))\n",
    "w=5\n",
    "y=y1*w-y2*w\n",
    "plt.plot(x,y,lw=2,color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tanh(x):     \n",
    "    return (1.0 - numpy.exp(-2*x))/(1.0 + numpy.exp(-2*x))\n",
    "\n",
    "def tanh_derivative(x):     \n",
    "    return (1 + tanh(x))*(1 - tanh(x))\n",
    "    \n",
    "class NeuralNetwork:\n",
    "    #network consists of a list of integers, indicating \n",
    "    #the number of neurons in each layer\n",
    "    def __init__(self, net_arch): \n",
    "        numpy.random.seed(0)                  \n",
    "        self.activity = tanh         \n",
    "        self.activity_derivative = tanh_derivative \n",
    "        self.layers = len(net_arch)         \n",
    "        self.steps_per_epoch = 1000\n",
    "        self.arch = net_arch        \n",
    "\n",
    "        self.weights = []         \n",
    "        #range of weight values (-1,1)         \n",
    "        for layer in range(len(net_arch) - 1):             \n",
    "            w = 2*numpy.random.rand(net_arch[layer] + 1, net_arch[layer+1]) - 1           \n",
    "            self.weights.append(w)\n",
    "\n",
    "    def fit(self, data, labels, learning_rate=0.1, epochs=10):         \n",
    "        #Add bias units to the input layer         \n",
    "        ones = numpy.ones((1, data.shape[0]))        \n",
    "        Z = numpy.concatenate((ones.T, data), axis=1)\n",
    "        training = epochs*self.steps_per_epoch\n",
    "\n",
    "\n",
    "        for k in range(training):             \n",
    "            if k % self.steps_per_epoch == 0:                  \n",
    "                #print ('epochs:', k/self.steps_per_epoch)    \n",
    "                print('epochs: {}'.format(k/self.steps_per_epoch))              \n",
    "                for s in data:                     \n",
    "                    print(s, nn.predict(s))\n",
    "\n",
    "            sample = numpy.random.randint(data.shape[0])            \n",
    "            y = [Z[sample]] \n",
    "\n",
    "            for i in range(len(self.weights)-1):                     \n",
    "                activation = numpy.dot(y[i], self.weights[i])                         \n",
    "                activity = self.activity(activation)  \n",
    "                #add the bias for the next layer                     \n",
    "                activity = numpy.concatenate((numpy.ones(1), numpy.array(activity)))                      \n",
    "                y.append(activity)   \n",
    "             \n",
    "            #last layer              \n",
    "            activation = numpy.dot(y[-1], self.weights[-1])             \n",
    "            activity = self.activity(activation)             \n",
    "            y.append(activity)\n",
    "                    \n",
    "            #error for the output layer             \n",
    "            error = labels[sample] - y[-1]             \n",
    "            delta_vec = [error * self.activity_derivative(y[-1])] \n",
    "\n",
    "            #we need to begin from the back from the next to last layer\n",
    "            for i in range(self.layers-2, 0, -1):  \n",
    "                #delta_vec [1].dot(self.weights[i][1:].T)                \n",
    "                error = delta_vec[-1].dot(self.weights[i][1:].T) \n",
    "                error = error*self.activity_derivative(y[i][1:])               \n",
    "                delta_vec.append(error)\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            delta_vec.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = y[i].reshape(1, nn.arch[i]+1) \n",
    " \n",
    "                delta = delta_vec[i].reshape(1, nn.arch[i+1])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "    def predict(self, x): \n",
    "        val = numpy.concatenate((numpy.ones(1).T, numpy.array(x)))      \n",
    "        for i in range(0, len(self.weights)):\n",
    "            val = self.activity(numpy.dot(val, self.weights[i]))\n",
    "            val = numpy.concatenate((numpy.ones(1).T, numpy.array(val)))\n",
    "            \n",
    "        return val[1]\n",
    "\n",
    "    def plot_decision_regions(self, X, y, points=200):\n",
    "        markers = ('o', '^')\n",
    "        colors = ('red', 'blue')\n",
    "        cmap = ListedColormap(colors)\n",
    "        # plot the decision surface\n",
    "        x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        \n",
    "        resolution = max(x1_max - x1_min, x2_max - x2_min)/float(points)\n",
    "        #resolution = 0.01\n",
    "     \n",
    "        xx1, xx2 = numpy.meshgrid(numpy.arange(x1_min, x1_max, resolution), numpy.arange(x2_min, x2_max, resolution))\n",
    "        input = numpy.array([xx1.ravel(), xx2.ravel()]).T \n",
    "        Z = numpy.empty(0)\n",
    "        for i in range(input.shape[0]):\n",
    "            val = nn.predict(numpy.array(input[i]))\n",
    "            if val < 0.5: val = 0 \n",
    "            if val >= 0.5: val = 1\n",
    "            Z = numpy.append(Z, val)\n",
    "\n",
    "        Z = Z.reshape(xx1.shape)\n",
    "        \n",
    "        plt.pcolormesh(xx1, xx2, Z, cmap=cmap)\n",
    "        plt.xlim(xx1.min(), xx1.max())\n",
    "        plt.ylim(xx2.min(), xx2.max())\n",
    "        # plot all samples\n",
    "\n",
    "        classes = [\"False\", \"True\"]\n",
    "        for idx, cl in enumerate(numpy.unique(y)):\n",
    "            plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=1.0, c=cmap(idx), marker=markers[idx], s=80, label=classes[idx])\n",
    "            \n",
    "        plt.xlabel('x-axis')            \n",
    "        plt.ylabel('y-axis')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "\n",
    "    X = numpy.array([[0, 0],\n",
    "                     [0, 1],\n",
    "                     [1, 0],\n",
    "                     [1, 1]])\n",
    "\n",
    "    y = numpy.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y, epochs=10)\n",
    "\n",
    "    print (\"Final prediction\")\n",
    "    for s in X:\n",
    "        print(s, nn.predict(s))\n",
    "        \n",
    "    nn.plot_decision_regions(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 圖像辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#數字圖資料集\n",
    "(X_train,Y_train),(X_test,Y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將60000*28*28矩陣轉成60000*784\n",
    "X_train=X_train.reshape(60000,784)\n",
    "X_test=X_test.reshape(10000,784)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#數字答案為0-9 轉換成0與1的元素向量  如4>[0,0,0,0,1,0,0,0,0,0] 、2>[0,0,1,0,0,0,0,0,0,0]\n",
    "classes=10\n",
    "Y_train=np_utils.to_categorical(Y_train,classes)\n",
    "Y_test=np_utils.to_categorical(Y_test,classes)\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=784#像速\n",
    "batch_size=100#每批樣本大小\n",
    "hidden_neurons=50#隱藏層神經元\n",
    "epochs=10#處理幾輪\n",
    "# main(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()  #定義model\n",
    "model.add(Dense(hidden_neurons,input_dim=input_size)) #加入層(緊密層) 產出個數100. 輸入個數784 次元\n",
    "model.add(Activation('sigmoid')) #啟動函數\n",
    "model.add(Dense(classes,input_dim=hidden_neurons))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#成本函數categorical_crossentropy  最佳化工具sgd(梯度下降)\n",
    "model.compile(loss=\"categorical_crossentropy\",metrics=['accuracy'],optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.1757 - acc: 0.6949\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.6434 - acc: 0.8547\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.4967 - acc: 0.8822\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.4291 - acc: 0.8943\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3855 - acc: 0.9027\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3559 - acc: 0.9084\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3346 - acc: 0.9115\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3205 - acc: 0.9140\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3011 - acc: 0.9198\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2934 - acc: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x35a19550>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#訓練、batch_size=每批用多少資料、nb_epoch處理幾次 、verbose=1(每個步驟都印出)\n",
    "model.fit(X_train,Y_train,batch_size=batch_size,nb_epoch=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 56us/step\n",
      "Test accuracy: 0.9252\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test,Y_test,verbose=1)\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#取得加權矩陣 (取得784(像素)*50(隱藏層數) +  50的矩陣)\n",
    "weights=model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm #圖形種類\n",
    "import numpy\n",
    "w=weights[0].T #變成50*784\n",
    "\n",
    "# for neuron in range(hidden_neurons):\n",
    "#     plt.imshow(numpy.reshape(w[neuron],(28,28)),\n",
    "#     cmap=cm.Greys_r)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "fig = plt.figure() \n",
    "for neuron in range(hidden_neurons):         \n",
    "    ax = fig.add_subplot(10, 10, neuron+1) #給予50個空間\n",
    "    ax.axis(\"off\")#軸取消\n",
    "    ax.imshow(numpy.reshape(w[neuron], (28, 28)), cmap = cm.Greys_r)#取得第n個784轉換成28*28 cm,Greys_r灰階\n",
    "\n",
    "plt.savefig(\"neuron_images.png\", dpi=300)    \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x35a19240>,\n",
       " <keras.layers.core.Activation at 0x35711e10>,\n",
       " <keras.layers.core.Dense at 0x35711b70>,\n",
       " <keras.layers.core.Activation at 0x35900d68>]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 較複雜的圖(有色彩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#數字圖資料集\n",
    "(X_train,Y_train),(X_test,Y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#將60000*28*28矩陣轉成60000*784\n",
    "X_train=X_train.reshape(50000,3072)\n",
    "X_test=X_test.reshape(10000,3072)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(numpy.reshape(X_train[100],(32,32,3)))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#數字答案為0-9 轉換成0與1的元素向量  如4>[0,0,0,0,1,0,0,0,0,0] 、2>[0,0,1,0,0,0,0,0,0,0]\n",
    "classes=10\n",
    "Y_train=np_utils.to_categorical(Y_train,classes)\n",
    "Y_test=np_utils.to_categorical(Y_test,classes)\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=3072#像速\n",
    "batch_size=100#每批樣本大小\n",
    "hidden_neurons=100#隱藏層神經元\n",
    "epochs=10#處理幾輪\n",
    "# main(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()  #定義model\n",
    "model.add(Dense(3000,input_dim=input_size)) #加入層(緊密層) 產出個數3000(神經元). 輸入個數3072 次元\n",
    "model.add(Activation('sigmoid')) #啟動函數\n",
    "model.add(Dense(2000,input_dim=2000)) #加入層(緊密層) 產出個數2000(神經元). 輸入個數3000 次元\n",
    "model.add(Activation('sigmoid')) #啟動函數\n",
    "model.add(Dense(classes,input_dim=2000))  #加入層(緊密層) 產出個數10(神經元). 輸入個數2000 次元\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#成本函數categorical_crossentropy  最佳化工具sgd(梯度下降)\n",
    "model.compile(loss=\"categorical_crossentropy\",metrics=['accuracy'],optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#訓練、batch_size=每批用多少資料、nb_epoch處理幾次 、verbose=1(每個步驟都印出) validation_split=0.1(訓練90% 驗證10%)\n",
    "model.fit(X_train,Y_train,batch_size=batch_size,nb_epoch=epochs,validation_split=0.1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score=model.evaluate(X_test,Y_test,verbose=1)\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#取得加權矩陣 (取得784(像素)*50(隱藏層數) +  50的矩陣)\n",
    "weights=model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 受限波茲曼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "VISIBLE_NODES = 784\n",
    "HIDDEN_NODES = 400\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "\n",
    "input_placeholder = tf.placeholder(\"float\", shape=(None, VISIBLE_NODES))\n",
    "\n",
    "weights = tf.Variable(tf.random_normal((VISIBLE_NODES, HIDDEN_NODES), mean=0.0, stddev=1. / VISIBLE_NODES))\n",
    "hidden_bias = tf.Variable(tf.zeros([HIDDEN_NODES]))\n",
    "visible_bias = tf.Variable(tf.zeros([VISIBLE_NODES]))\n",
    "\n",
    "hidden_activation = tf.nn.sigmoid(tf.matmul(input_placeholder, weights) + hidden_bias)\n",
    "visible_reconstruction = tf.nn.sigmoid(tf.matmul(hidden_activation, tf.transpose(weights)) + visible_bias)\n",
    "\n",
    "final_hidden_activation = tf.nn.sigmoid(tf.matmul(visible_reconstruction, weights) + hidden_bias)\n",
    "\n",
    "positive_phase = tf.matmul(tf.transpose(input_placeholder), hidden_activation)\n",
    "negative_phase = tf.matmul(tf.transpose(visible_reconstruction), final_hidden_activation)\n",
    "\n",
    "weight_update = weights.assign_add(LEARNING_RATE * (positive_phase - negative_phase))\n",
    "visible_bias_update = visible_bias.assign_add(LEARNING_RATE *\n",
    "                                              tf.reduce_mean(input_placeholder - visible_reconstruction, 0))\n",
    "hidden_bias_update = hidden_bias.assign_add(LEARNING_RATE *\n",
    "                                            tf.reduce_mean(hidden_activation - final_hidden_activation, 0))\n",
    "\n",
    "train_op = tf.group(weight_update, visible_bias_update, hidden_bias_update)\n",
    "\n",
    "loss_op = tf.reduce_sum(tf.square(input_placeholder - visible_reconstruction))\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "session.run(tf.initialize_all_variables())\n",
    "\n",
    "current_epochs = 0\n",
    "\n",
    "for i in range(20):\n",
    "    total_loss = 0\n",
    "    while mnist.train.epochs_completed == current_epochs:\n",
    "        batch_inputs, batch_labels = mnist.train.next_batch(100)\n",
    "        _, reconstruction_loss = session.run([train_op, loss_op], feed_dict={input_placeholder: batch_inputs})\n",
    "        total_loss += reconstruction_loss\n",
    "\n",
    "    print(\"epochs %s loss %s\" % (current_epochs, reconstruction_loss))\n",
    "    current_epochs = mnist.train.epochs_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstruction=session.run(visible_reconstruction,feed_dict={input_placeholder:[mnist.train.images[0]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷積概念"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "#image為int(數字圖片編號)\n",
    "def main(image,im_filter):\n",
    "    im=X_train[image]\n",
    "    #定義新圖形、大小為圖片數據 寬-2*高-2\n",
    "    width=im.shape[0]\n",
    "    height=im.shape[1]\n",
    "    imC=numpy.zeros((width-2,height-2))\n",
    "    \n",
    "    \n",
    "    #進行卷積\n",
    "    for row in range(1,width-1):\n",
    "        for col in range(1,height-1):\n",
    "            for i in range(len(im_filter[0])):\n",
    "                for j in range(len(im_filter)):\n",
    "                    imC[row-1][col-1]+=im[row-1+i][col-1+j]*im_filter[i][j]\n",
    "#             #數字不大於255(灰皆色範圍)\n",
    "            if imC[row-1][col-1]>255:\n",
    "                imC[row-1][col-1]=255\n",
    "            elif imC[row-1][col-1]<0:\n",
    "                imC[row-1][col-1]=0\n",
    "    plt.imshow(im,cmap=cm.Greys_r)\n",
    "    plt.show()\n",
    "    plt.imshow(imC/255,cmap=cm.Greys_r)\n",
    "    plt.show()  \n",
    "    \n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    #載入資料\n",
    "    (X_train,Y_train),(X_test,Y_test)=mnist.load_data()\n",
    "    \n",
    "    #建立filter\n",
    "    blur=[[1./9,1./9,1./9],[1./9,1./9,1./9],[1./9,1./9,1./9]]\n",
    "    edges=[[1,1,1],[0,-8,0],[1,1,1]]\n",
    "    \n",
    "    #跑卷積\n",
    "    main(1,edges)\n",
    "    main(1,blur)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano\n",
    "import matplotlib.pyplot as plt\n",
    "import theano.tensor as T\n",
    "from theano.tensor.nnet import conv\n",
    "import skimage.data\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda update --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --ignore-installed scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=scipy.imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#數字圖資料集\n",
    "(X_train,Y_train),(X_test,Y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#將60000*28*28矩陣轉成60000*784\n",
    "X_train=X_train.reshape(60000,28,28,1)\n",
    "X_test=X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#數字答案為0-9 轉換成0與1的元素向量  如4>[0,0,0,0,1,0,0,0,0,0] 、2>[0,0,1,0,0,0,0,0,0,0]\n",
    "classes=10\n",
    "Y_train=np_utils.to_categorical(Y_train,classes)\n",
    "Y_test=np_utils.to_categorical(Y_test,classes)\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=784#像速\n",
    "batch_size=100#每批樣本大小\n",
    "hidden_neurons=200#隱藏層神經元\n",
    "epochs=30#處理幾輪\n",
    "# main(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_train/=255\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()  #定義model\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(28,28,1))) #加入層(緊密層) 產出個數100. 輸入個數784 次元\n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Convolution2D(32,(3,3))) #加入層(緊密層) 產出個數100. 輸入個數784 次元\n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(hidden_neurons)) \n",
    "model.add(Activation('relu'))      \n",
    "model.add(Dense(classes)) \n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#成本函數categorical_crossentropy  最佳化工具sgd(梯度下降)\n",
    "model.compile(loss=\"categorical_crossentropy\",metrics=['accuracy'],optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.2244 - acc: 0.9322\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0556 - acc: 0.9831\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.0378 - acc: 0.9885\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0286 - acc: 0.9915\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.0219 - acc: 0.9936\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0170 - acc: 0.9951\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0136 - acc: 0.9960\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0106 - acc: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6a66e1d0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#訓練、batch_size=每批用多少資料、nb_epoch處理幾次 、verbose=1(每個步驟都印出)\n",
    "model.fit(X_train,Y_train,batch_size=batch_size,nb_epoch=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 567us/step\n",
      "Test accuracy: 0.9889\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test,Y_test,verbose=1)\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#取得加權矩陣 (取得784(像素)*50(隱藏層數) +  50的矩陣)\n",
    "weights=model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 9 into shape (28,28,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-bb86a57f07be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneuron\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#給予50個空間\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"off\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#軸取消\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGreys_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#取得第n個784轉換成28*28 cm,Greys_r灰階\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"neuron_images.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;33m*\u001b[0m \u001b[1;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mraise\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meach\u001b[0m \u001b[0melement\u001b[0m \u001b[0mof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0ma\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mand\u001b[0m \u001b[0mthus\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mBa\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuppose\u001b[0m \u001b[0mthat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m       \u001b[0;31m`\u001b[0m\u001b[0mi\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m       \u001b[1;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mBa\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mposition\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mBchoices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msame\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 9 into shape (28,28,1)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm #圖形種類\n",
    "import numpy\n",
    "w=weights[0].T #變成50*784\n",
    "\n",
    "# for neuron in range(hidden_neurons):\n",
    "#     plt.imshow(numpy.reshape(w[neuron],(28,28)),\n",
    "#     cmap=cm.Greys_r)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "fig = plt.figure() \n",
    "for neuron in range(hidden_neurons):         \n",
    "    ax = fig.add_subplot(20, 20, neuron+1) #給予50個空間\n",
    "    ax.axis(\"off\")#軸取消\n",
    "    ax.imshow(numpy.reshape(w[neuron], (28, 28)), cmap = cm.Greys_r)#取得第n個784轉換成28*28 cm,Greys_r灰階\n",
    "\n",
    "plt.savefig(\"neuron_images.png\", dpi=300)    \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/8\n",
      " 1700/54000 [..............................] - ETA: 1:58 - loss: 1.7324 - acc: 0.5006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-c8bac6cb89f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adadelta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np     \n",
    "# np.random.seed(0)  #for reproducibility            \n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential #model\n",
    "from keras.layers import Dense, Activation #緊密層、啟動函數\n",
    "from keras.layers import Convolution2D, MaxPooling2D# 卷積、池化\n",
    "from keras.layers import Dropout, Flatten #隨機神經元退出 、平坦化\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 100     \n",
    "hidden_neurons = 200\n",
    "classes = 10     \n",
    "epochs = 8\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)     \n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')     \n",
    "X_test = X_test.astype('float32')     \n",
    "X_train /= 255     \n",
    "X_test /= 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train, classes)     \n",
    "Y_test = np_utils.to_categorical(Y_test, classes)\n",
    "\n",
    "model = Sequential() \n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(28, 28, 1))) #32種3*3的filters \n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, (3, 3)))  \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))  \n",
    "               \n",
    "model.add(Flatten())\n",
    " \n",
    "model.add(Dense(hidden_neurons)) \n",
    "model.add(Activation('relu'))      \n",
    "model.add(Dense(classes)) \n",
    "model.add(Activation('softmax'))\n",
    "     \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adadelta')\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split = 0.1, verbose=1)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 6.0131 - acc: 0.6197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x346ce160>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import utils\n",
    "\n",
    "(data, labels), (X_test, Y_test) = mnist.load_data()\n",
    "X_test=X_test.reshape(10000,784)\n",
    "data=data.reshape(60000,784)\n",
    "labels = utils.to_categorical(labels, num_classes=10)\n",
    "# 这部分返回一个张量\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# 层的实例是可调用的，它以张量为参数，并且返回一个张量\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 这部分创建了一个包含输入层和三个全连接层的模型\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels)  # 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b25a08dfd5ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mjson_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#將模型變json字串 可存放為文字檔\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#將json字串變成model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_string = model.to_json() #將模型變json字串 可存放為文字檔\n",
    "model = model_from_json(json_string) #將json字串變成model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=3\n",
    "\n",
    "#每走一步輸入得到的數值\n",
    "def step(s,x,U,W):\n",
    "    return x*U+s*W\n",
    "\n",
    "#向後傳遞\n",
    "def forward(X,U,W):\n",
    "    S=np.zeros((number_of_samples,sequence_length+1))\n",
    "    for t in range(0,sequence_length):\n",
    "        S[:,t+1]=step(S[:,t],X[:,t],U,W)\n",
    "    return S\n",
    "#成本函數(均方誤差)\n",
    "# cost=np.sum((targets-y)**2)\n",
    "def bacjward(X,S,targets,W):\n",
    "    y=S[:,-1]\n",
    "    gS=2.0*(y-targets)\n",
    "    gU,gW=0,0\n",
    "    for k in range(sequence_len,0,-1):\n",
    "        gU+=np.sum(gS*X[:,k-1])\n",
    "        gW+=np.sum(gS*S[:,k-1])\n",
    "        gS=gS*W\n",
    "    return gU,gW\n",
    "\n",
    "learning_rate=0.0005\n",
    "parameters=(-2,0)\n",
    "for i in range(number_iterations):\n",
    "    S=forward(X,parameters(0),parameters(1))\n",
    "    gradients=backward(X,S,targets,parameters(1))\n",
    "    parameters=((p-gp*learning_rate) for p,gp in zip(parameters,gradients))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters=(-2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-188555973c63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "parameters(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
